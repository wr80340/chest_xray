{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 27 02:47:04 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\r\n",
      "| 35%   50C    P8    13W / 250W |      3MiB / 11016MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwr80340\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.20 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.19<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">splendid-wind-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wr80340/chest_xray\" target=\"_blank\">https://wandb.ai/wr80340/chest_xray</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wr80340/chest_xray/runs/1fb3imka\" target=\"_blank\">https://wandb.ai/wr80340/chest_xray/runs/1fb3imka</a><br/>\n",
       "                Run data is saved locally in <code>/tf/liao/wandb/run-20210227_024706-1fb3imka</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1fb3imka)</h1><iframe src=\"https://wandb.ai/wr80340/chest_xray/runs/1fb3imka\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd332566e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "wandb.init(project = 'chest_xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/liao'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PNEUMONIA': 3875, 'NORMAL': 1341})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_path = []\n",
    "training_labels = []\n",
    "val_path = []\n",
    "val_labels = []\n",
    "testing_path = []\n",
    "testing_labels = []\n",
    "\n",
    "classes = ['NORMAL','PNEUMONIA']\n",
    "for c in classes:  \n",
    "    for dirpath, dnames, fnames in os.walk(\"./chest_xray/train/\" + c):\n",
    "        for f in fnames:\n",
    "            training_path.append(\"./chest_xray/train/\" + c + \"/\" + f)\n",
    "            training_labels.append(c)\n",
    "for c in classes:  \n",
    "    for dirpath, dnames, fnames in os.walk(\"./chest_xray/val/\" + c):\n",
    "        for f in fnames:\n",
    "            val_path.append(\"./chest_xray/val/\" + c + \"/\" + f)\n",
    "            val_labels.append(c)\n",
    "for c in classes:  \n",
    "    for dirpath, dnames, fnames in os.walk(\"./chest_xray/test/\" + c):\n",
    "        for f in fnames:\n",
    "            testing_path.append(\"./chest_xray/test/\" + c + \"/\" + f)\n",
    "            testing_labels.append(c)\n",
    "            \n",
    "dt = list(zip(training_path, training_labels))\n",
    "random.shuffle(dt)\n",
    "training_path, training_labels = zip(*dt)\n",
    "training_labels = list(training_labels)\n",
    "training_path = list(training_path)\n",
    "collections.Counter(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0]\n",
      "['PNEUMONIA', 'NORMAL', 'NORMAL', 'PNEUMONIA', 'NORMAL']\n"
     ]
    }
   ],
   "source": [
    "label_to_index = dict((name, index) for index,name in enumerate(classes))\n",
    "index_to_label = dict((index, name) for index,name in enumerate(classes))\n",
    "training_index = [label_to_index[lab] for lab in training_labels]\n",
    "testing_index = [label_to_index[lab] for lab in testing_labels]\n",
    "val_index = [label_to_index[lab] for lab in val_labels]\n",
    "print(training_index[:5])\n",
    "print(training_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data : #3662, validation data #1570, testing data #624\n"
     ]
    }
   ],
   "source": [
    "training_index += val_index\n",
    "training_path += val_path\n",
    "training_path, val_path, training_index, val_index = train_test_split(training_path, training_index, test_size = 0.3, random_state = 1122)\n",
    "print(\"training data : #{:0}, validation data #{:0}, testing data #{:0}\".format(len(training_index), len(val_index), len(testing_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_CROPPED = 200\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH = 224,224,3\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "EPOCH = 50\n",
    "REPEATS = 3\n",
    "last_layer_length = len(classes)\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "train_loss = tf.keras.metrics.Mean()\n",
    "val_loss = tf.keras.metrics.Mean()\n",
    "test_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr = LR)\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, index):\n",
    "    # convert path to img\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMAGE_DEPTH)\n",
    "    img = tf.image.resize_with_pad(img, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "#     img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "    \n",
    "    return img, index\n",
    "\n",
    "def augment_function(image, index):\n",
    "    # location mapping\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    # color mapping\n",
    "    trigger = tf.random.uniform([])\n",
    "    if trigger < 0.1:\n",
    "        image = tf.image.random_crop(image, [IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, IMAGE_DEPTH])\n",
    "    elif trigger < 0.3:\n",
    "        image = tf.image.adjust_contrast(image, 3)\n",
    "    elif trigger < 0.5:\n",
    "        image = tf.image.adjust_saturation(image, 3)\n",
    "    elif trigger < 0.7:\n",
    "        image = tf.image.adjust_hue(image, 0.5)\n",
    "        \n",
    "    # assert size = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    \n",
    "    return image, index\n",
    "\n",
    "def standardize(image, index):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    return image, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((training_path, training_index))\n",
    "dataset_train = dataset_train.repeat(REPEATS)\n",
    "dataset_train = dataset_train.map(load_image)\n",
    "# dataset_train = dataset_train.map(augment_function)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "dataset_train = dataset_train.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val_path, val_index))\n",
    "dataset_val = dataset_val.map(load_image)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE)\n",
    "dataset_val = dataset_val.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((testing_path, testing_index))\n",
    "dataset_test = dataset_test.map(load_image)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE)\n",
    "dataset_test = dataset_test.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet101 (Model)            multiple                  42658176  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               51380736  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 94,190,146\n",
      "Trainable params: 51,530,306\n",
      "Non-trainable params: 42,659,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_inputs = tf.keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))\n",
    "resnet = tf.keras.applications.ResNet101(include_top = False, weights = 'imagenet')\n",
    "for layers in resnet.layers:\n",
    "    layers.trainable = False\n",
    "x = resnet(img_inputs)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "out = tf.keras.layers.Dense(last_layer_length, activation = \"softmax\")(x)\n",
    "model = tf.keras.Model(inputs=img_inputs, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, index):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(image)\n",
    "        loss = scce(index, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(index, preds)\n",
    "\n",
    "@tf.function\n",
    "def val_step(image, index):\n",
    "    preds = model(image)\n",
    "    loss = scce(index, preds)\n",
    "    \n",
    "    val_loss(loss)\n",
    "    val_accuracy(index, preds) \n",
    "    \n",
    "@tf.function\n",
    "def test_step(image, index):\n",
    "    preds = model(image)\n",
    "    loss = scce(index, preds)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(index, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5, train accuracy 0.98, train loss 0.91, val accuracy 0.96, val loss 1.96\n",
      "EPOCH 10, train accuracy 0.99, train loss 0.46, val accuracy 0.96, val loss 1.73\n",
      "EPOCH 15, train accuracy 0.99, train loss 0.31, val accuracy 0.97, val loss 1.65\n",
      "EPOCH 20, train accuracy 0.99, train loss 0.23, val accuracy 0.97, val loss 1.61\n",
      "EPOCH 25, train accuracy 1.00, train loss 0.19, val accuracy 0.97, val loss 1.59\n",
      "EPOCH 30, train accuracy 1.00, train loss 0.16, val accuracy 0.97, val loss 1.58\n",
      "EPOCH 35, train accuracy 1.00, train loss 0.13, val accuracy 0.97, val loss 1.58\n",
      "EPOCH 40, train accuracy 1.00, train loss 0.12, val accuracy 0.97, val loss 1.58\n",
      "EPOCH 45, train accuracy 1.00, train loss 0.10, val accuracy 0.97, val loss 1.58\n",
      "EPOCH 50, train accuracy 1.00, train loss 0.09, val accuracy 0.97, val loss 1.59\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):    \n",
    "    for (train_image, train_index), (val_image, val_index) in zip(dataset_train, dataset_val): \n",
    "        train_step(train_image, train_index)\n",
    "        val_step(val_image, val_index)\n",
    "\n",
    "    wandb.log({\n",
    "        \"training accuracy\" : train_accuracy.result().numpy(),\n",
    "        \"training loss\" : train_loss.result().numpy(),\n",
    "        \"validation accuracy\" : val_accuracy.result().numpy(),\n",
    "        \"validation loss\" : val_loss.result().numpy(),\n",
    "    })\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        tmp = \"EPOCH {:0}, train accuracy {:.2f}, train loss {:.2f}, val accuracy {:.2f}, val loss {:.2f}\"\n",
    "        print(tmp.format(epoch+1, train_accuracy.result().numpy(), train_loss.result().numpy(), val_accuracy.result().numpy(), val_loss.result().numpy()))\n",
    "\n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "val_loss.reset_states()\n",
    "val_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.80, test loss 25.75\n"
     ]
    }
   ],
   "source": [
    "for test_image, test_index in dataset_test: \n",
    "    test_step(test_image, test_index)\n",
    "tmp = \"test accuracy {:.2f}, test loss {:.2f}\"\n",
    "print(tmp.format(test_accuracy.result().numpy(), test_loss.result().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
